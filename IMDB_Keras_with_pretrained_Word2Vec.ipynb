{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mazenmagdii/IMDB-Sentiment-Classification/blob/main/IMDB_Keras_with_pretrained_Word2Vec.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "9dUYIRxtwsUQ"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense,Embedding,LSTM,Dropout,Bidirectional,GRU\n",
        "from tensorflow.keras.callbacks import EarlyStopping,ModelCheckpoint\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.layers import SpatialDropout1D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten,BatchNormalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UnOS7mrvsPy6",
        "outputId": "7495f8d0-6715-4904-9caf-35bf7f55d13c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "\u001b[1m17464789/17464789\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n"
          ]
        }
      ],
      "source": [
        "from gensim.models import Word2Vec\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.datasets import imdb\n",
        "(x_train,y_train),(x_test,y_test)=imdb.load_data(num_words=20000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "-LH8WXwP426S"
      },
      "outputs": [],
      "source": [
        "X=np.concatenate((x_train,x_test))\n",
        "Y=np.concatenate((y_train,y_test))\n",
        "x_train,x_temp,y_train,y_temp=train_test_split(X,Y,test_size=0.3,shuffle=True,random_state=42)\n",
        "x_val,x_test,y_val,y_test=train_test_split(x_temp,y_temp,test_size=0.5,shuffle=True,random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rFDQGtMO0sP1",
        "outputId": "cf93b0b1-38ca-4e16-a096-0096135af9a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
            "\u001b[1m1641221/1641221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1us/step\n"
          ]
        }
      ],
      "source": [
        "word_i= imdb.get_word_index()\n",
        "reverse_word_i=dict([(value,key) for (key,value) in word_i.items()])\n",
        "def decode_review(encoded_review):\n",
        "  return ' '.join([reverse_word_i.get(i-3,'?') for i in encoded_review])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "DkFboheU1Xi0"
      },
      "outputs": [],
      "source": [
        "train_texts = [decode_review(review) for review in x_train]\n",
        "val_texts = [decode_review(review) for review in x_val]\n",
        "test_texts = [decode_review(review) for review in x_test]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "vu0VVdDw6B8_"
      },
      "outputs": [],
      "source": [
        "tok=Tokenizer(num_words=20000)\n",
        "tok.fit_on_texts(train_texts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "qkm1701k79pq"
      },
      "outputs": [],
      "source": [
        "X_train_seq = tok.texts_to_sequences(train_texts)\n",
        "X_val_seq = tok.texts_to_sequences(val_texts)\n",
        "X_test_seq = tok.texts_to_sequences(test_texts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "c_f0kSyp8Nkq"
      },
      "outputs": [],
      "source": [
        "max_length = 500\n",
        "X_train_pad = pad_sequences(X_train_seq, maxlen=max_length)\n",
        "X_val_pad = pad_sequences(X_val_seq, maxlen=max_length)\n",
        "X_test_pad = pad_sequences(X_test_seq, maxlen=max_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "jPm-ORX-88NH"
      },
      "outputs": [],
      "source": [
        "train_sentences = [review.split() for review in train_texts]\n",
        "word2vec_model = Word2Vec(sentences=train_sentences, vector_size=100, window=5, min_count=1, workers=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "OSbhK4LJA1GK"
      },
      "outputs": [],
      "source": [
        "embedding_matrix = np.zeros((20000, 100))\n",
        "for word, i in tok.word_index.items():\n",
        "    if i < 10000:\n",
        "        try:\n",
        "            embedding_vector = word2vec_model.wv[word]\n",
        "            if embedding_vector is not None:\n",
        "                embedding_matrix[i] = embedding_vector\n",
        "        except KeyError:\n",
        "            continue"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bNjQwj78_a1F"
      },
      "source": [
        "LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q0cTeZtH_cLu",
        "outputId": "1a4507bf-d7bb-4e69-bb18-a3a436c4340c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "model = Sequential([\n",
        "    Embedding(input_dim=20000, output_dim=100, weights=[embedding_matrix], input_length=max_length, trainable=False, mask_zero=True),\n",
        "    SpatialDropout1D(0.2),\n",
        "    LSTM(110, recurrent_dropout=0.2),\n",
        "    Dense(1, activation='sigmoid')\n",
        "\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.01), metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('best_model.keras')"
      ],
      "metadata": {
        "id": "bvbmrook05N9"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "rBZfotBvBec1"
      },
      "outputs": [],
      "source": [
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=True, patience=10)\n",
        "mc = ModelCheckpoint('best_weights.keras', monitor='val_accuracy', mode='max', verbose=True, save_best_only=True)\n",
        "rlr = ReduceLROnPlateau(monitor='val_loss', factor=0.25, patience=3, verbose=True,min_lr=0.0000001 )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rNAW38Ax0g6n",
        "outputId": "2d1b571c-c323-4efa-fee4-405db250ad4a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 925ms/step - accuracy: 0.7576 - loss: 0.4905\n",
            "Epoch 1: val_accuracy improved from -inf to 0.87400, saving model to best_weights.keras\n",
            "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m545s\u001b[0m 992ms/step - accuracy: 0.7577 - loss: 0.4903 - val_accuracy: 0.8740 - val_loss: 0.3069 - learning_rate: 0.0100\n",
            "Epoch 2/30\n",
            "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 928ms/step - accuracy: 0.8527 - loss: 0.3463\n",
            "Epoch 2: val_accuracy improved from 0.87400 to 0.87733, saving model to best_weights.keras\n",
            "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m569s\u001b[0m 1s/step - accuracy: 0.8527 - loss: 0.3463 - val_accuracy: 0.8773 - val_loss: 0.2965 - learning_rate: 0.0100\n",
            "Epoch 3/30\n",
            "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 934ms/step - accuracy: 0.8624 - loss: 0.3224\n",
            "Epoch 3: val_accuracy improved from 0.87733 to 0.88200, saving model to best_weights.keras\n",
            "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m560s\u001b[0m 1s/step - accuracy: 0.8624 - loss: 0.3224 - val_accuracy: 0.8820 - val_loss: 0.2840 - learning_rate: 0.0100\n",
            "Epoch 4/30\n",
            "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 931ms/step - accuracy: 0.8630 - loss: 0.3188\n",
            "Epoch 4: val_accuracy improved from 0.88200 to 0.88213, saving model to best_weights.keras\n",
            "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m559s\u001b[0m 996ms/step - accuracy: 0.8630 - loss: 0.3188 - val_accuracy: 0.8821 - val_loss: 0.2904 - learning_rate: 0.0100\n",
            "Epoch 5/30\n",
            "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 929ms/step - accuracy: 0.8735 - loss: 0.3052\n",
            "Epoch 5: val_accuracy did not improve from 0.88213\n",
            "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m564s\u001b[0m 998ms/step - accuracy: 0.8735 - loss: 0.3052 - val_accuracy: 0.8792 - val_loss: 0.2884 - learning_rate: 0.0100\n",
            "Epoch 6/30\n",
            "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 935ms/step - accuracy: 0.8652 - loss: 0.3160\n",
            "Epoch 6: val_accuracy did not improve from 0.88213\n",
            "\n",
            "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
            "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m562s\u001b[0m 1s/step - accuracy: 0.8652 - loss: 0.3160 - val_accuracy: 0.8759 - val_loss: 0.2858 - learning_rate: 0.0100\n",
            "Epoch 7/30\n",
            "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 938ms/step - accuracy: 0.8724 - loss: 0.2997\n",
            "Epoch 7: val_accuracy improved from 0.88213 to 0.88720, saving model to best_weights.keras\n",
            "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m562s\u001b[0m 1s/step - accuracy: 0.8724 - loss: 0.2997 - val_accuracy: 0.8872 - val_loss: 0.2707 - learning_rate: 0.0025\n",
            "Epoch 8/30\n",
            "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 929ms/step - accuracy: 0.8767 - loss: 0.2889\n",
            "Epoch 8: val_accuracy improved from 0.88720 to 0.88893, saving model to best_weights.keras\n",
            "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m559s\u001b[0m 996ms/step - accuracy: 0.8767 - loss: 0.2889 - val_accuracy: 0.8889 - val_loss: 0.2662 - learning_rate: 0.0025\n",
            "Epoch 9/30\n",
            "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 930ms/step - accuracy: 0.8831 - loss: 0.2788\n",
            "Epoch 9: val_accuracy improved from 0.88893 to 0.89027, saving model to best_weights.keras\n",
            "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m564s\u001b[0m 999ms/step - accuracy: 0.8831 - loss: 0.2788 - val_accuracy: 0.8903 - val_loss: 0.2630 - learning_rate: 0.0025\n",
            "Epoch 10/30\n",
            "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 930ms/step - accuracy: 0.8880 - loss: 0.2738\n",
            "Epoch 10: val_accuracy improved from 0.89027 to 0.89467, saving model to best_weights.keras\n",
            "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m560s\u001b[0m 996ms/step - accuracy: 0.8880 - loss: 0.2738 - val_accuracy: 0.8947 - val_loss: 0.2618 - learning_rate: 0.0025\n",
            "Epoch 11/30\n",
            "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 933ms/step - accuracy: 0.8898 - loss: 0.2715\n",
            "Epoch 11: val_accuracy did not improve from 0.89467\n",
            "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m562s\u001b[0m 997ms/step - accuracy: 0.8898 - loss: 0.2715 - val_accuracy: 0.8895 - val_loss: 0.2683 - learning_rate: 0.0025\n",
            "Epoch 12/30\n",
            "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 926ms/step - accuracy: 0.8847 - loss: 0.2723\n",
            "Epoch 12: val_accuracy did not improve from 0.89467\n",
            "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m548s\u001b[0m 1s/step - accuracy: 0.8847 - loss: 0.2723 - val_accuracy: 0.8921 - val_loss: 0.2598 - learning_rate: 0.0025\n",
            "Epoch 13/30\n",
            "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 932ms/step - accuracy: 0.8919 - loss: 0.2649\n",
            "Epoch 13: val_accuracy did not improve from 0.89467\n",
            "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m562s\u001b[0m 1s/step - accuracy: 0.8919 - loss: 0.2649 - val_accuracy: 0.8928 - val_loss: 0.2587 - learning_rate: 0.0025\n",
            "Epoch 14/30\n",
            "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 929ms/step - accuracy: 0.8890 - loss: 0.2657\n",
            "Epoch 14: val_accuracy did not improve from 0.89467\n",
            "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m556s\u001b[0m 991ms/step - accuracy: 0.8890 - loss: 0.2657 - val_accuracy: 0.8904 - val_loss: 0.2599 - learning_rate: 0.0025\n",
            "Epoch 15/30\n",
            "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 926ms/step - accuracy: 0.8913 - loss: 0.2616\n",
            "Epoch 15: val_accuracy improved from 0.89467 to 0.89493, saving model to best_weights.keras\n",
            "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m544s\u001b[0m 994ms/step - accuracy: 0.8913 - loss: 0.2616 - val_accuracy: 0.8949 - val_loss: 0.2552 - learning_rate: 0.0025\n",
            "Epoch 16/30\n",
            "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 930ms/step - accuracy: 0.8968 - loss: 0.2555\n",
            "Epoch 16: val_accuracy improved from 0.89493 to 0.89547, saving model to best_weights.keras\n",
            "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m568s\u001b[0m 1s/step - accuracy: 0.8967 - loss: 0.2555 - val_accuracy: 0.8955 - val_loss: 0.2542 - learning_rate: 0.0025\n",
            "Epoch 17/30\n",
            "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 928ms/step - accuracy: 0.8925 - loss: 0.2532\n",
            "Epoch 17: val_accuracy did not improve from 0.89547\n",
            "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m561s\u001b[0m 1s/step - accuracy: 0.8925 - loss: 0.2532 - val_accuracy: 0.8955 - val_loss: 0.2530 - learning_rate: 0.0025\n",
            "Epoch 18/30\n",
            "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 927ms/step - accuracy: 0.8940 - loss: 0.2541\n",
            "Epoch 18: val_accuracy did not improve from 0.89547\n",
            "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m554s\u001b[0m 989ms/step - accuracy: 0.8940 - loss: 0.2541 - val_accuracy: 0.8949 - val_loss: 0.2537 - learning_rate: 0.0025\n",
            "Epoch 19/30\n",
            "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 932ms/step - accuracy: 0.8946 - loss: 0.2540\n",
            "Epoch 19: val_accuracy did not improve from 0.89547\n",
            "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m565s\u001b[0m 995ms/step - accuracy: 0.8946 - loss: 0.2540 - val_accuracy: 0.8941 - val_loss: 0.2514 - learning_rate: 0.0025\n",
            "Epoch 20/30\n",
            "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 928ms/step - accuracy: 0.8976 - loss: 0.2476\n",
            "Epoch 20: val_accuracy did not improve from 0.89547\n",
            "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m549s\u001b[0m 1s/step - accuracy: 0.8976 - loss: 0.2476 - val_accuracy: 0.8953 - val_loss: 0.2514 - learning_rate: 0.0025\n",
            "Epoch 21/30\n",
            "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 930ms/step - accuracy: 0.9014 - loss: 0.2429\n",
            "Epoch 21: val_accuracy improved from 0.89547 to 0.89880, saving model to best_weights.keras\n",
            "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m556s\u001b[0m 992ms/step - accuracy: 0.9014 - loss: 0.2429 - val_accuracy: 0.8988 - val_loss: 0.2476 - learning_rate: 0.0025\n",
            "Epoch 22/30\n",
            "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 923ms/step - accuracy: 0.8996 - loss: 0.2476\n",
            "Epoch 22: val_accuracy did not improve from 0.89880\n",
            "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m559s\u001b[0m 988ms/step - accuracy: 0.8996 - loss: 0.2476 - val_accuracy: 0.8980 - val_loss: 0.2493 - learning_rate: 0.0025\n",
            "Epoch 23/30\n",
            "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 927ms/step - accuracy: 0.9015 - loss: 0.2419\n",
            "Epoch 23: val_accuracy did not improve from 0.89880\n",
            "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m563s\u001b[0m 990ms/step - accuracy: 0.9015 - loss: 0.2419 - val_accuracy: 0.8983 - val_loss: 0.2439 - learning_rate: 0.0025\n",
            "Epoch 24/30\n",
            "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 924ms/step - accuracy: 0.9003 - loss: 0.2452\n",
            "Epoch 24: val_accuracy improved from 0.89880 to 0.90160, saving model to best_weights.keras\n",
            "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m560s\u001b[0m 987ms/step - accuracy: 0.9003 - loss: 0.2452 - val_accuracy: 0.9016 - val_loss: 0.2456 - learning_rate: 0.0025\n",
            "Epoch 25/30\n",
            "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 929ms/step - accuracy: 0.9016 - loss: 0.2397\n",
            "Epoch 25: val_accuracy did not improve from 0.90160\n",
            "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m566s\u001b[0m 994ms/step - accuracy: 0.9016 - loss: 0.2397 - val_accuracy: 0.9001 - val_loss: 0.2483 - learning_rate: 0.0025\n",
            "Epoch 26/30\n",
            "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 914ms/step - accuracy: 0.9010 - loss: 0.2444\n",
            "Epoch 26: val_accuracy did not improve from 0.90160\n",
            "\n",
            "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
            "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m536s\u001b[0m 979ms/step - accuracy: 0.9010 - loss: 0.2444 - val_accuracy: 0.8965 - val_loss: 0.2514 - learning_rate: 0.0025\n",
            "Epoch 27/30\n",
            "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 915ms/step - accuracy: 0.9037 - loss: 0.2373\n",
            "Epoch 27: val_accuracy did not improve from 0.90160\n",
            "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m562s\u001b[0m 980ms/step - accuracy: 0.9037 - loss: 0.2373 - val_accuracy: 0.8997 - val_loss: 0.2478 - learning_rate: 6.2500e-04\n",
            "Epoch 28/30\n",
            "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 917ms/step - accuracy: 0.9045 - loss: 0.2338\n",
            "Epoch 28: val_accuracy did not improve from 0.90160\n",
            "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m561s\u001b[0m 978ms/step - accuracy: 0.9045 - loss: 0.2338 - val_accuracy: 0.8985 - val_loss: 0.2471 - learning_rate: 6.2500e-04\n",
            "Epoch 29/30\n",
            "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 915ms/step - accuracy: 0.9033 - loss: 0.2353\n",
            "Epoch 29: val_accuracy did not improve from 0.90160\n",
            "\n",
            "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
            "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m569s\u001b[0m 990ms/step - accuracy: 0.9033 - loss: 0.2353 - val_accuracy: 0.8972 - val_loss: 0.2474 - learning_rate: 6.2500e-04\n",
            "Epoch 30/30\n",
            "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 917ms/step - accuracy: 0.9018 - loss: 0.2367\n",
            "Epoch 30: val_accuracy did not improve from 0.90160\n",
            "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m557s\u001b[0m 983ms/step - accuracy: 0.9018 - loss: 0.2367 - val_accuracy: 0.8992 - val_loss: 0.2461 - learning_rate: 1.5625e-04\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(X_train_pad, y_train, epochs=30, batch_size=64, validation_data=(X_val_pad, y_val), verbose=True, callbacks=[es,mc,rlr])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xHo3DPhwCci1",
        "outputId": "bcb2177e-bb6e-4938-e019-929c7ede5380"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 139ms/step - accuracy: 0.8991 - loss: 0.2541\n",
            "Test Accuracy: 0.8955\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model on the test set\n",
        "x_test_seq = tok.texts_to_sequences([' '.join([reverse_word_i.get(i - 3, '?') for i in review]) for review in x_test])\n",
        "x_test_padded = pad_sequences(x_test_seq, maxlen=max_length)\n",
        "test_loss, test_accuracy = model.evaluate(x_test_padded, y_test)\n",
        "print(f'Test Accuracy: {test_accuracy:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "0WRK4rRoT9x_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1ded0a2-faed-4e4c-d67d-54ea8a63a8a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step\n",
            "Prediction: [0.01208363]\n",
            "Negative review!\n"
          ]
        }
      ],
      "source": [
        "test_review = [\"The movie wasn't good, i didn't enjoy watching it.It was a horrible one.\"]\n",
        "review_sequence = tok.texts_to_sequences(test_review)\n",
        "padded_review = pad_sequences(review_sequence, maxlen=max_length)\n",
        "\n",
        "prediction = model.predict(padded_review)\n",
        "\n",
        "print(f\"Prediction: {prediction[0]}\")\n",
        "\n",
        "if prediction >= 0.5:\n",
        "    print(\"Positive review!\")\n",
        "else:\n",
        "    print(\"Negative review!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sTzOkrSM_VFd"
      },
      "source": [
        "GRU+CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "c7rLD-8ldXFj",
        "outputId": "e424d3bd-930d-494f-bbc2-c6c1a0c965c4"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              │ ?                           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">2,000,000</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ spatial_dropout1d_1                  │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout1D</span>)                   │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                    │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)       │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ gru_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                          │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_1                │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)              │ ?                           │       \u001b[38;5;34m2,000,000\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ spatial_dropout1d_1                  │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "│ (\u001b[38;5;33mSpatialDropout1D\u001b[0m)                   │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)                    │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling1d_1 (\u001b[38;5;33mMaxPooling1D\u001b[0m)       │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ gru_1 (\u001b[38;5;33mGRU\u001b[0m)                          │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_1                │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,000,000</span> (7.63 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,000,000\u001b[0m (7.63 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,000,000</span> (7.63 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,000,000\u001b[0m (7.63 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "model1 = Sequential([\n",
        "      Embedding(input_dim=20000, output_dim=100, weights=[embedding_matrix], input_length=max_length, trainable=False, mask_zero=True),\n",
        "      SpatialDropout1D(0.35),\n",
        "      Conv1D(filters=70, kernel_size=3, activation='relu',padding='valid',strides=1),\n",
        "      MaxPooling1D(pool_size=4),\n",
        "      GRU(100, recurrent_dropout=0.1),\n",
        "      BatchNormalization(),\n",
        "      Dense(1, activation='sigmoid')\n",
        "])\n",
        "model1.summary()\n",
        "# Compile the model\n",
        "model1.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.001,clipnorm=1.0), metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gh-f6qfBAZ_F"
      },
      "outputs": [],
      "source": [
        "model1.load_weights('best_model1.keras')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5DMInc_QgCY1"
      },
      "outputs": [],
      "source": [
        "mc1 = ModelCheckpoint('best_model1.keras', monitor='val_accuracy', mode='max', verbose=True, save_best_only=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Lul5ToTfFjt",
        "outputId": "3716fa00-6421-4ca9-bb27-7feb1316e8a5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'conv1d_1' (of type Conv1D) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1094/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - accuracy: 0.5634 - loss: 0.7291\n",
            "Epoch 1: val_accuracy improved from -inf to 0.50747, saving model to best_model1.keras\n",
            "\u001b[1m1094/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 167ms/step - accuracy: 0.5635 - loss: 0.7290 - val_accuracy: 0.5075 - val_loss: 0.6899 - learning_rate: 0.0010\n",
            "Epoch 2/50\n",
            "\u001b[1m1094/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - accuracy: 0.7124 - loss: 0.5775\n",
            "Epoch 2: val_accuracy improved from 0.50747 to 0.70293, saving model to best_model1.keras\n",
            "\u001b[1m1094/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 167ms/step - accuracy: 0.7124 - loss: 0.5775 - val_accuracy: 0.7029 - val_loss: 0.6868 - learning_rate: 0.0010\n",
            "Epoch 3/50\n",
            "\u001b[1m1094/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - accuracy: 0.7575 - loss: 0.5201\n",
            "Epoch 3: val_accuracy improved from 0.70293 to 0.77693, saving model to best_model1.keras\n",
            "\u001b[1m1094/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 166ms/step - accuracy: 0.7576 - loss: 0.5201 - val_accuracy: 0.7769 - val_loss: 0.6049 - learning_rate: 0.0010\n",
            "Epoch 4/50\n",
            "\u001b[1m1094/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - accuracy: 0.7830 - loss: 0.4723\n",
            "Epoch 4: val_accuracy improved from 0.77693 to 0.79533, saving model to best_model1.keras\n",
            "\u001b[1m1094/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 165ms/step - accuracy: 0.7830 - loss: 0.4723 - val_accuracy: 0.7953 - val_loss: 0.6790 - learning_rate: 0.0010\n",
            "Epoch 5/50\n",
            "\u001b[1m1094/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - accuracy: 0.7838 - loss: 0.4786\n",
            "Epoch 5: val_accuracy did not improve from 0.79533\n",
            "\u001b[1m1094/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 165ms/step - accuracy: 0.7838 - loss: 0.4786 - val_accuracy: 0.7428 - val_loss: 0.6566 - learning_rate: 0.0010\n",
            "Epoch 6/50\n",
            "\u001b[1m1094/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - accuracy: 0.7915 - loss: 0.4587\n",
            "Epoch 6: val_accuracy did not improve from 0.79533\n",
            "\n",
            "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\u001b[1m1094/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m182s\u001b[0m 166ms/step - accuracy: 0.7915 - loss: 0.4587 - val_accuracy: 0.7805 - val_loss: 0.6530 - learning_rate: 0.0010\n",
            "Epoch 7/50\n",
            "\u001b[1m1094/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - accuracy: 0.8109 - loss: 0.4256\n",
            "Epoch 7: val_accuracy improved from 0.79533 to 0.80640, saving model to best_model1.keras\n",
            "\u001b[1m1094/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 167ms/step - accuracy: 0.8109 - loss: 0.4256 - val_accuracy: 0.8064 - val_loss: 0.5573 - learning_rate: 2.5000e-04\n",
            "Epoch 8/50\n",
            "\u001b[1m1094/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - accuracy: 0.8115 - loss: 0.4192\n",
            "Epoch 8: val_accuracy improved from 0.80640 to 0.80907, saving model to best_model1.keras\n",
            "\u001b[1m1094/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 167ms/step - accuracy: 0.8115 - loss: 0.4192 - val_accuracy: 0.8091 - val_loss: 0.5485 - learning_rate: 2.5000e-04\n",
            "Epoch 9/50\n",
            "\u001b[1m1094/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - accuracy: 0.8167 - loss: 0.4060\n",
            "Epoch 9: val_accuracy did not improve from 0.80907\n",
            "\u001b[1m1094/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 164ms/step - accuracy: 0.8167 - loss: 0.4060 - val_accuracy: 0.7777 - val_loss: 0.5719 - learning_rate: 2.5000e-04\n",
            "Epoch 10/50\n",
            "\u001b[1m1094/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - accuracy: 0.8191 - loss: 0.4070\n",
            "Epoch 10: val_accuracy improved from 0.80907 to 0.81027, saving model to best_model1.keras\n",
            "\u001b[1m1094/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 168ms/step - accuracy: 0.8191 - loss: 0.4070 - val_accuracy: 0.8103 - val_loss: 0.5526 - learning_rate: 2.5000e-04\n",
            "Epoch 11/50\n",
            "\u001b[1m1094/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - accuracy: 0.8255 - loss: 0.3949\n",
            "Epoch 11: val_accuracy improved from 0.81027 to 0.81227, saving model to best_model1.keras\n",
            "\u001b[1m1094/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 166ms/step - accuracy: 0.8255 - loss: 0.3949 - val_accuracy: 0.8123 - val_loss: 0.5327 - learning_rate: 2.5000e-04\n",
            "Epoch 12/50\n",
            "\u001b[1m1094/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - accuracy: 0.8262 - loss: 0.3944\n",
            "Epoch 12: val_accuracy did not improve from 0.81227\n",
            "\u001b[1m1094/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 167ms/step - accuracy: 0.8262 - loss: 0.3944 - val_accuracy: 0.7884 - val_loss: 0.5338 - learning_rate: 2.5000e-04\n",
            "Epoch 13/50\n",
            "\u001b[1m1094/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - accuracy: 0.8301 - loss: 0.3856\n",
            "Epoch 13: val_accuracy did not improve from 0.81227\n",
            "\u001b[1m1094/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 165ms/step - accuracy: 0.8301 - loss: 0.3856 - val_accuracy: 0.8080 - val_loss: 0.5718 - learning_rate: 2.5000e-04\n",
            "Epoch 14/50\n",
            "\u001b[1m1094/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - accuracy: 0.8347 - loss: 0.3833\n",
            "Epoch 14: val_accuracy did not improve from 0.81227\n",
            "\n",
            "Epoch 14: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "\u001b[1m1094/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 166ms/step - accuracy: 0.8347 - loss: 0.3833 - val_accuracy: 0.8024 - val_loss: 0.5623 - learning_rate: 2.5000e-04\n",
            "Epoch 15/50\n",
            "\u001b[1m1094/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - accuracy: 0.8342 - loss: 0.3812\n",
            "Epoch 15: val_accuracy improved from 0.81227 to 0.81827, saving model to best_model1.keras\n",
            "\u001b[1m1094/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 166ms/step - accuracy: 0.8342 - loss: 0.3812 - val_accuracy: 0.8183 - val_loss: 0.5811 - learning_rate: 6.2500e-05\n",
            "Epoch 16/50\n",
            "\u001b[1m1094/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - accuracy: 0.8381 - loss: 0.3721\n",
            "Epoch 16: val_accuracy did not improve from 0.81827\n",
            "\u001b[1m1094/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 166ms/step - accuracy: 0.8381 - loss: 0.3721 - val_accuracy: 0.7908 - val_loss: 0.5053 - learning_rate: 6.2500e-05\n",
            "Epoch 17/50\n",
            "\u001b[1m1094/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - accuracy: 0.8387 - loss: 0.3717\n",
            "Epoch 17: val_accuracy did not improve from 0.81827\n",
            "\u001b[1m1094/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 168ms/step - accuracy: 0.8387 - loss: 0.3716 - val_accuracy: 0.7787 - val_loss: 0.5423 - learning_rate: 6.2500e-05\n",
            "Epoch 18/50\n",
            "\u001b[1m1094/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - accuracy: 0.8380 - loss: 0.3734\n",
            "Epoch 18: val_accuracy did not improve from 0.81827\n",
            "\u001b[1m1094/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 167ms/step - accuracy: 0.8380 - loss: 0.3734 - val_accuracy: 0.7965 - val_loss: 0.4733 - learning_rate: 6.2500e-05\n",
            "Epoch 19/50\n",
            "\u001b[1m1094/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - accuracy: 0.8448 - loss: 0.3636\n",
            "Epoch 19: val_accuracy did not improve from 0.81827\n",
            "\u001b[1m1094/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 166ms/step - accuracy: 0.8448 - loss: 0.3636 - val_accuracy: 0.7775 - val_loss: 0.5061 - learning_rate: 6.2500e-05\n",
            "Epoch 20/50\n",
            "\u001b[1m1094/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - accuracy: 0.8390 - loss: 0.3697\n",
            "Epoch 20: val_accuracy improved from 0.81827 to 0.81907, saving model to best_model1.keras\n",
            "\u001b[1m1094/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 167ms/step - accuracy: 0.8390 - loss: 0.3697 - val_accuracy: 0.8191 - val_loss: 0.5179 - learning_rate: 6.2500e-05\n",
            "Epoch 21/50\n",
            "\u001b[1m1094/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - accuracy: 0.8428 - loss: 0.3653\n",
            "Epoch 21: val_accuracy did not improve from 0.81907\n",
            "\n",
            "Epoch 21: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
            "\u001b[1m1094/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m182s\u001b[0m 167ms/step - accuracy: 0.8428 - loss: 0.3653 - val_accuracy: 0.8049 - val_loss: 0.4752 - learning_rate: 6.2500e-05\n",
            "Epoch 22/50\n",
            "\u001b[1m1094/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - accuracy: 0.8463 - loss: 0.3574\n",
            "Epoch 22: val_accuracy did not improve from 0.81907\n",
            "\u001b[1m1094/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 167ms/step - accuracy: 0.8463 - loss: 0.3574 - val_accuracy: 0.8069 - val_loss: 0.4805 - learning_rate: 1.5625e-05\n",
            "Epoch 23/50\n",
            "\u001b[1m1094/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - accuracy: 0.8424 - loss: 0.3637\n",
            "Epoch 23: val_accuracy did not improve from 0.81907\n",
            "\u001b[1m1094/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 167ms/step - accuracy: 0.8424 - loss: 0.3637 - val_accuracy: 0.8055 - val_loss: 0.4663 - learning_rate: 1.5625e-05\n",
            "Epoch 24/50\n",
            "\u001b[1m1094/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - accuracy: 0.8414 - loss: 0.3619\n",
            "Epoch 24: val_accuracy did not improve from 0.81907\n",
            "\u001b[1m1094/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 168ms/step - accuracy: 0.8414 - loss: 0.3619 - val_accuracy: 0.7997 - val_loss: 0.4807 - learning_rate: 1.5625e-05\n",
            "Epoch 25/50\n",
            "\u001b[1m1094/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - accuracy: 0.8393 - loss: 0.3626\n",
            "Epoch 25: val_accuracy did not improve from 0.81907\n",
            "\u001b[1m1094/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 168ms/step - accuracy: 0.8393 - loss: 0.3626 - val_accuracy: 0.8027 - val_loss: 0.4693 - learning_rate: 1.5625e-05\n",
            "Epoch 26/50\n",
            "\u001b[1m1094/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - accuracy: 0.8459 - loss: 0.3579\n",
            "Epoch 26: val_accuracy did not improve from 0.81907\n",
            "\n",
            "Epoch 26: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
            "\u001b[1m1094/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 167ms/step - accuracy: 0.8459 - loss: 0.3579 - val_accuracy: 0.8019 - val_loss: 0.4910 - learning_rate: 1.5625e-05\n",
            "Epoch 27/50\n",
            "\u001b[1m1094/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - accuracy: 0.8427 - loss: 0.3659\n",
            "Epoch 27: val_accuracy did not improve from 0.81907\n",
            "\u001b[1m1094/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 166ms/step - accuracy: 0.8427 - loss: 0.3659 - val_accuracy: 0.8073 - val_loss: 0.4646 - learning_rate: 3.9063e-06\n",
            "Epoch 28/50\n",
            "\u001b[1m1094/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - accuracy: 0.8427 - loss: 0.3662\n",
            "Epoch 28: val_accuracy did not improve from 0.81907\n",
            "\u001b[1m1094/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 165ms/step - accuracy: 0.8427 - loss: 0.3662 - val_accuracy: 0.7981 - val_loss: 0.4869 - learning_rate: 3.9063e-06\n",
            "Epoch 29/50\n",
            "\u001b[1m1094/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - accuracy: 0.8427 - loss: 0.3602\n",
            "Epoch 29: val_accuracy did not improve from 0.81907\n",
            "\u001b[1m1094/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 167ms/step - accuracy: 0.8427 - loss: 0.3602 - val_accuracy: 0.7925 - val_loss: 0.4878 - learning_rate: 3.9063e-06\n",
            "Epoch 30/50\n",
            "\u001b[1m1094/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - accuracy: 0.8430 - loss: 0.3584\n",
            "Epoch 30: val_accuracy did not improve from 0.81907\n",
            "\n",
            "Epoch 30: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
            "\u001b[1m1094/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 168ms/step - accuracy: 0.8430 - loss: 0.3584 - val_accuracy: 0.7987 - val_loss: 0.4874 - learning_rate: 3.9063e-06\n",
            "Epoch 31/50\n",
            "\u001b[1m1094/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - accuracy: 0.8416 - loss: 0.3604\n",
            "Epoch 31: val_accuracy did not improve from 0.81907\n",
            "\u001b[1m1094/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 167ms/step - accuracy: 0.8416 - loss: 0.3604 - val_accuracy: 0.7976 - val_loss: 0.4780 - learning_rate: 9.7656e-07\n",
            "Epoch 32/50\n",
            "\u001b[1m1094/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - accuracy: 0.8453 - loss: 0.3578\n",
            "Epoch 32: val_accuracy did not improve from 0.81907\n",
            "\u001b[1m1094/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 167ms/step - accuracy: 0.8453 - loss: 0.3578 - val_accuracy: 0.8005 - val_loss: 0.4880 - learning_rate: 9.7656e-07\n",
            "Epoch 33/50\n",
            "\u001b[1m1094/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - accuracy: 0.8466 - loss: 0.3586\n",
            "Epoch 33: val_accuracy did not improve from 0.81907\n",
            "\n",
            "Epoch 33: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
            "\u001b[1m1094/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 167ms/step - accuracy: 0.8466 - loss: 0.3586 - val_accuracy: 0.7879 - val_loss: 0.4967 - learning_rate: 9.7656e-07\n",
            "Epoch 34/50\n",
            "\u001b[1m1094/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - accuracy: 0.8430 - loss: 0.3652\n",
            "Epoch 34: val_accuracy did not improve from 0.81907\n",
            "\u001b[1m1094/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m182s\u001b[0m 166ms/step - accuracy: 0.8430 - loss: 0.3652 - val_accuracy: 0.8011 - val_loss: 0.4795 - learning_rate: 2.4414e-07\n",
            "Epoch 35/50\n",
            "\u001b[1m1094/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - accuracy: 0.8424 - loss: 0.3615\n",
            "Epoch 35: val_accuracy did not improve from 0.81907\n",
            "\u001b[1m1094/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 167ms/step - accuracy: 0.8424 - loss: 0.3615 - val_accuracy: 0.7945 - val_loss: 0.4987 - learning_rate: 2.4414e-07\n",
            "Epoch 36/50\n",
            "\u001b[1m1094/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - accuracy: 0.8476 - loss: 0.3561\n",
            "Epoch 36: val_accuracy did not improve from 0.81907\n",
            "\n",
            "Epoch 36: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
            "\u001b[1m1094/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 168ms/step - accuracy: 0.8476 - loss: 0.3561 - val_accuracy: 0.8139 - val_loss: 0.4668 - learning_rate: 2.4414e-07\n",
            "Epoch 37/50\n",
            "\u001b[1m1094/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - accuracy: 0.8485 - loss: 0.3577\n",
            "Epoch 37: val_accuracy did not improve from 0.81907\n",
            "\u001b[1m1094/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 166ms/step - accuracy: 0.8485 - loss: 0.3577 - val_accuracy: 0.8109 - val_loss: 0.4530 - learning_rate: 1.0000e-07\n",
            "Epoch 38/50\n",
            "\u001b[1m1094/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - accuracy: 0.8425 - loss: 0.3622\n",
            "Epoch 38: val_accuracy did not improve from 0.81907\n",
            "\u001b[1m1094/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 166ms/step - accuracy: 0.8425 - loss: 0.3622 - val_accuracy: 0.7847 - val_loss: 0.5030 - learning_rate: 1.0000e-07\n",
            "Epoch 39/50\n",
            "\u001b[1m1094/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - accuracy: 0.8457 - loss: 0.3577\n",
            "Epoch 39: val_accuracy did not improve from 0.81907\n",
            "\u001b[1m1094/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 164ms/step - accuracy: 0.8457 - loss: 0.3577 - val_accuracy: 0.7884 - val_loss: 0.5115 - learning_rate: 1.0000e-07\n",
            "Epoch 40/50\n",
            "\u001b[1m1094/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - accuracy: 0.8419 - loss: 0.3631\n",
            "Epoch 40: val_accuracy did not improve from 0.81907\n",
            "\u001b[1m1094/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 164ms/step - accuracy: 0.8419 - loss: 0.3631 - val_accuracy: 0.8036 - val_loss: 0.4605 - learning_rate: 1.0000e-07\n",
            "Epoch 41/50\n",
            "\u001b[1m1094/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - accuracy: 0.8422 - loss: 0.3653\n",
            "Epoch 41: val_accuracy did not improve from 0.81907\n",
            "\u001b[1m1094/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 164ms/step - accuracy: 0.8422 - loss: 0.3653 - val_accuracy: 0.8059 - val_loss: 0.4681 - learning_rate: 1.0000e-07\n",
            "Epoch 42/50\n",
            "\u001b[1m1094/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - accuracy: 0.8447 - loss: 0.3622\n",
            "Epoch 42: val_accuracy did not improve from 0.81907\n",
            "\u001b[1m1094/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 167ms/step - accuracy: 0.8447 - loss: 0.3622 - val_accuracy: 0.8144 - val_loss: 0.4609 - learning_rate: 1.0000e-07\n",
            "Epoch 43/50\n",
            "\u001b[1m1094/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - accuracy: 0.8451 - loss: 0.3614\n",
            "Epoch 43: val_accuracy did not improve from 0.81907\n",
            "\u001b[1m1094/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 171ms/step - accuracy: 0.8451 - loss: 0.3614 - val_accuracy: 0.8040 - val_loss: 0.4712 - learning_rate: 1.0000e-07\n",
            "Epoch 44/50\n",
            "\u001b[1m1094/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - accuracy: 0.8413 - loss: 0.3660\n",
            "Epoch 44: val_accuracy did not improve from 0.81907\n",
            "\u001b[1m1094/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 165ms/step - accuracy: 0.8413 - loss: 0.3660 - val_accuracy: 0.8093 - val_loss: 0.4658 - learning_rate: 1.0000e-07\n",
            "Epoch 45/50\n",
            "\u001b[1m1094/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - accuracy: 0.8440 - loss: 0.3603\n",
            "Epoch 45: val_accuracy did not improve from 0.81907\n",
            "\u001b[1m1094/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m182s\u001b[0m 167ms/step - accuracy: 0.8440 - loss: 0.3603 - val_accuracy: 0.8071 - val_loss: 0.4803 - learning_rate: 1.0000e-07\n",
            "Epoch 46/50\n",
            "\u001b[1m1094/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - accuracy: 0.8413 - loss: 0.3645\n",
            "Epoch 46: val_accuracy did not improve from 0.81907\n",
            "\u001b[1m1094/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 167ms/step - accuracy: 0.8413 - loss: 0.3645 - val_accuracy: 0.8047 - val_loss: 0.4668 - learning_rate: 1.0000e-07\n",
            "Epoch 47/50\n",
            "\u001b[1m1094/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - accuracy: 0.8456 - loss: 0.3585\n",
            "Epoch 47: val_accuracy did not improve from 0.81907\n",
            "\u001b[1m1094/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 165ms/step - accuracy: 0.8456 - loss: 0.3585 - val_accuracy: 0.8064 - val_loss: 0.4590 - learning_rate: 1.0000e-07\n",
            "Epoch 47: early stopping\n"
          ]
        }
      ],
      "source": [
        "history1 = model1.fit(X_train_pad, y_train, epochs=50, batch_size=32, validation_data=(X_val_pad, y_val), verbose=True, callbacks=[es,mc1,rlr])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zU_loDn-iX9w",
        "outputId": "10a16001-1036-4e38-faff-b5e2ac53e4c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 51ms/step - accuracy: 0.8169 - loss: 0.5209\n",
            "Test Accuracy: 0.8156\n"
          ]
        }
      ],
      "source": [
        "x_test_seq = tok.texts_to_sequences([' '.join([reverse_word_i.get(i - 3, '?') for i in review]) for review in x_test])\n",
        "x_test_padded = pad_sequences(x_test_seq, maxlen=max_length)\n",
        "test_loss, test_accuracy = model1.evaluate(x_test_padded, y_test)\n",
        "print(f'Test Accuracy: {test_accuracy:.4f}')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNlp9vNii9vbEP6mfKabcEC",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}